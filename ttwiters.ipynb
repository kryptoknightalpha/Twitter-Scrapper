{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Python Script to scrape tweets from Twitter with python through the Twitter Search (Rest) API.\n",
    "I designed it to search twitter for various keywords tweeted by users and return the result in table.\n",
    "\"\"\"\n",
    "\n",
    "'''Details in here  \n",
    "Api Keys:  ' '\n",
    "\n",
    "Api Key Secret: ' '\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import date, datetime\n",
    "import sys\n",
    "import base64\n",
    "import requests\n",
    "import re\n",
    "\n",
    "def getUserName():\n",
    "    while True:\n",
    "        try:\n",
    "            username = input(\"Enter the Twitter usernames you'd like to track, seperated by a comma (example: @Username1, @Username2):\")\n",
    "            if username[0][0] != '@':\n",
    "                raise ValueError\n",
    "            else:\n",
    "                userList = username.replace(\" \", \"\").replace(\"@\", \"from:@\").replace(\",\", \" OR \")\n",
    "\n",
    "            return userList\n",
    "        except ValueError:\n",
    "            print(\"Hmmm... \" + username + \" do not look like a valid usernames. Let's try that again.\")\n",
    "\n",
    "\n",
    "def getKeyWords():\n",
    "    while True:\n",
    "        try: \n",
    "            keywords = input(\"Enter the keywords you'd like to track, seperated by a comma (example: stealth, action): \")\n",
    "            keywords = keywords.replace(\", \", \",\").split(\",\")\n",
    "            \n",
    "            for keyword in keywords:\n",
    "                if (\" \") in keyword:\n",
    "                    raise ValueError # this will send it to the print message and back to the input option            \n",
    "            \n",
    "            keywords = \" OR \".join(keywords)\n",
    "            return keywords\n",
    "        \n",
    "        except ValueError:\n",
    "            print(\"Hmmm...keywords can only be single words, not phrases. Let's try that again.\")\n",
    "\n",
    "\n",
    "def getBlackListWords():\n",
    "    while True:\n",
    "        try: \n",
    "            blacklistWords = input(\"Enter the words you'd like to avoid in your search, seperated by a comma (example: Stealth, action): \")\n",
    "            blacklistWords = blacklistWords.replace(\", \", \",\").split(\",\")\n",
    "            \n",
    "            for word in blacklistWords:\n",
    "                if (\" \") in word:\n",
    "                    raise ValueError # this will send it to the print message and back to the input option  \n",
    "            \n",
    "            blacklistWords = \" -\".join(blacklistWords)\n",
    "            blacklistWords = \"-\" + blacklistWords\n",
    "            return blacklistWords\n",
    "        \n",
    "        except ValueError:\n",
    "            print(\"Hmmm...blacklistWordsed words can only be single words, not phrases. Let's try that again.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def format_usernames():\n",
    "   \n",
    "   # Format usernames for search\n",
    "   usernames = user['usernames'][0]\n",
    "   usernames = usernames.replace(\" \", \"\").split(\"OR\")\n",
    "   \n",
    "   # Organize first set of usernames\n",
    "   usernames_one = usernames[0]\n",
    "   for item in usernames[1:11]:\n",
    "       usernames_one += ' OR ' + item\n",
    "       \n",
    "   # Organize second set if > 11 usernames   \n",
    "   try: \n",
    "       usernames_two = usernames[11]\n",
    "   \n",
    "       for item in usernames[12:23]:\n",
    "           usernames_two += ' OR ' + item\n",
    "\n",
    "   except IndexError:\n",
    "       usernames_two = []\n",
    "       \n",
    "       \n",
    "   # Organize second set if > 24 usernames    \n",
    "   try: \n",
    "       usernames_three = usernames[23]\n",
    "   \n",
    "       for item in usernames[24:35]:\n",
    "           usernames_three += ' OR ' + item\n",
    "\n",
    "   except IndexError:\n",
    "       usernames_three = []\n",
    "       \n",
    "       \n",
    "   # Organize second set if > 36 usernames   \n",
    "   try: \n",
    "       usernames_four = usernames[35]\n",
    "   \n",
    "       for item in usernames[36:47]:\n",
    "           usernames_four += ' OR ' + item\n",
    "\n",
    "   except IndexError:\n",
    "       usernames_four = []\n",
    "       \n",
    "       \n",
    "    # Organize second set if > 48 usernames   \n",
    "   try: \n",
    "       usernames_five = usernames[47]\n",
    "   \n",
    "       for item in usernames[48:59]:\n",
    "           usernames_five += ' OR ' + item\n",
    "\n",
    "   except IndexError:\n",
    "       usernames_five = []\n",
    "              \n",
    "       \n",
    "    # Organize second set if > 60 usernames   \n",
    "   try: \n",
    "       usernames_six = usernames[59]\n",
    "   \n",
    "       for item in usernames[60:71]:\n",
    "           usernames_six += ' OR ' + item\n",
    "\n",
    "   except IndexError:\n",
    "       usernames_six = []\n",
    "       \n",
    "   return usernames_one, usernames_two, usernames_three, usernames_four, usernames_five, usernames_six\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        user = pd.read_csv(\"twitter_settings.csv\", index_col=0)\n",
    "        keywords = user['keywords'][0]\n",
    "        blacklist = user['blacklist'][0]\n",
    "        \n",
    "        usernames_one, usernames_two, usernames_three, usernames_four, usernames_five, usernames_six = format_usernames()\n",
    "    \n",
    "\n",
    "    except IOError:\n",
    "        \n",
    "        print(\"Let's get you setup!\")\n",
    "        \n",
    "        # Get Scrape Settings\n",
    "        usernames = getUserName()\n",
    "        keywords = getKeyWords()\n",
    "        blacklist = getBlackListWords()\n",
    "        date = date.today().strftime('%Y-%m-%d')\n",
    "        filename = sys.argv[0]\n",
    "        \n",
    "        # create user dataframe\n",
    "        col = {\"usernames\":usernames, \"keywords\":keywords, \"blacklist\":blacklist}\n",
    "        user = pd.DataFrame(col, index= [date])\n",
    "        user.to_csv(\"twitter_settings.csv\", encoding='utf-8', index=True)\n",
    "        \n",
    "        usernames_one, usernames_two, usernames_three, usernames_four, usernames_five, usernames_six = format_usernames()\n",
    "            \n",
    "        print(\"Your twitter settings are all setup! You can edit these search settings directly through the file named 'twitter_settings.csv'. You can find this file at \" + filename)\n",
    "\n",
    "    try:\n",
    "        f= open(\"credentials.txt\",\"r\")\n",
    "        client_key = contents.replace(\"=\",\",\").split(\",\")[1]\n",
    "        client_secret = contents.replace(\"=\",\",\").split(\",\")[3]\n",
    "    except:\n",
    "        f= open(\"credentials.txt\",\"w+\")\n",
    "        client_key = input('Client Key: ')\n",
    "        client_secret = input('Client Secret: ')\n",
    "        f.write(\"client_key={}, client_secret={}\".format(client_key,client_secret))\n",
    "        f.close()\n",
    "\n",
    "    #Reformat the keys and encode them\n",
    "    key_secret = '{}:{}'.format(client_key, client_secret).encode('ascii')\n",
    "\n",
    "    # Transform from bytes to bytes that can be printed\n",
    "    b64_encoded_key = base64.b64encode(key_secret)\n",
    "\n",
    "    #Transform from bytes back into Unicode\n",
    "    b64_encoded_key = b64_encoded_key.decode('ascii')\n",
    "\n",
    "    #Adding authorization to base URL \n",
    "\n",
    "    base_url = 'https://api.twitter.com/'\n",
    "    auth_url = '{}oauth2/token'.format(base_url)\n",
    "\n",
    "    auth_headers = {\n",
    "        'Authorization': 'Basic {}'.format(b64_encoded_key),\n",
    "        'Content-Type': 'application/x-www-form-urlencoded;charset=UTF-8'}\n",
    "\n",
    "    auth_data = {\n",
    "        'grant_type': 'client_credentials'}\n",
    "\n",
    "    auth_resp = requests.post(auth_url, headers=auth_headers, data=auth_data)\n",
    "\n",
    "\n",
    "    #Creating bearer token\n",
    "\n",
    "    access_token = auth_resp.json()['access_token']\n",
    "\n",
    "    search_headers = {\n",
    "        'Authorization': 'Bearer {}'.format(access_token)}\n",
    "\n",
    "\n",
    "\n",
    "    def Call_api(username_group):\n",
    "\n",
    "        #Adding search parameters: ('OR' = or)('+' = and)('-' = not) *(space interpreted as &)\n",
    "\n",
    "        #search_params = {'q': username_group + \" + \" + keywords + \" + \" + blacklist,}\n",
    "        search_params = {'q': username_group + \" + \" + str(keywords) + \" + \" + str(blacklist)}\n",
    "\n",
    "\n",
    "        #Adding Twitter search API to base URL\n",
    "        search_url = '{}1.1/search/tweets.json'.format(base_url)\n",
    "\n",
    "        #Putting all elements together and execute request \n",
    "        resp = requests.get(search_url, headers=search_headers, params=search_params)\n",
    "\n",
    "\n",
    "        #Get the data from the 1st request\n",
    "        import json\n",
    "        scrape = json.loads(resp.content)\n",
    "        \n",
    "            #Extracting desired data from 1st scrape as lists\n",
    "        users = []\n",
    "        tweet_dates = []\n",
    "        kw_tweets = []\n",
    "\n",
    "\n",
    "        for tweet in scrape['statuses']:\n",
    "            users.append(tweet['user']['screen_name'])\n",
    "            kw_tweets.append(tweet['text'])\n",
    "            dates = datetime.strptime(tweet['created_at'][4:-11], '%b %d %H:%M:%S').strftime('%m/%d %H:%M')\n",
    "            tweet_dates.append(dates)\n",
    "            \n",
    "            \n",
    "        #Creating df1 via pandas\n",
    "        #Creating columns names and adding their data\n",
    "        scrape = {\n",
    "            \"User\" : users,\n",
    "            \"Date\" : tweet_dates,\n",
    "            \"Tweet\" : kw_tweets,   \n",
    "        }\n",
    "\n",
    "        #Create DataFrame\n",
    "        df = pd.DataFrame(scrape)\n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "    DataFrame = Call_api(usernames_one)\n",
    "\n",
    "    if usernames_two != []:\n",
    "    \n",
    "        df = Call_api(usernames_two)\n",
    "        \n",
    "        DataFrame = pd.concat([DataFrame,df], ignore_index=True)\n",
    "    elif usernames_three != []:\n",
    "        df = Call_api(usernames_three)\n",
    "        \n",
    "        DataFrame = pd.concat([DataFrame,df], ignore_index=True)\n",
    "    elif usernames_four != []:\n",
    "        df = Call_api(usernames_four)\n",
    "        \n",
    "        DataFrame = pd.concat([DataFrame,df], ignore_index=True)\n",
    "    elif usernames_five != []:\n",
    "        df = Call_api(usernames_five)\n",
    "        \n",
    "        DataFrame = pd.concat([DataFrame,df], ignore_index=True)\n",
    "    elif usernames_six != []:\n",
    "        df = Call_api(usernames_six)\n",
    "        \n",
    "        DataFrame = pd.concat([DataFrame,df], ignore_index=True)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    DataFrame\n",
    "\n",
    "    DataFrame['Tweet'].replace('(https://t.co)/(\\w+)', r'\\1', regex=True).drop_duplicates()\n",
    "    tweets = DataFrame.loc[DataFrame['Tweet'].replace('(https://t.co)/(\\w+)', r'\\1', regex=True).drop_duplicates().index]\n",
    "    tweets = tweets.sort_values(by=['Date'], ascending=False)\n",
    "    tweets.reset_index(drop=True, inplace=True)\n",
    "    tweets\n",
    "\n",
    "    #Export data to CSV file\n",
    "    tweets.to_csv(\"kw_tweets.csv\", encoding='utf-8', index=False)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "  #Export table to Excel without index column\n",
    "    \n",
    "    writer = pd.ExcelWriter(\"kw_tweets.xlsx\", engine='xlsxwriter')\n",
    "    df.to_excel(writer, index=False)\n",
    "    writer.save()    \n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# assume your dictionary object is called 'my_dict'\n",
    "df = pd.DataFrame.from_dict(DataFrame)\n",
    "\n",
    "# Export table to Excel without index column\n",
    "writer = pd.ExcelWriter(\"kw_tweets.xlsx\", engine='xlsxwriter')\n",
    "df.to_excel(writer, index=False)\n",
    "writer.save()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
